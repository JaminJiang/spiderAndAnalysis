{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Indexing http://www.chinagrain.cn/\n",
      "update urllist set posnegscore = -0.251314 where url = 'http://www.chinagrain.cn/'\n",
      "1\n",
      "Indexing http://www.chinagrain.cn/liangyou/2016/9/5/20169513582448889.shtml\n",
      "update urllist set posnegscore = 7.573376 where url = 'http://www.chinagrain.cn/liangyou/2016/9/5/20169513582448889.shtml'\n",
      "2\n",
      "Indexing http://www.chinagrain.cn/biz/20127/201271715505375798.html\n",
      "update urllist set posnegscore = 5.084434 where url = 'http://www.chinagrain.cn/biz/20127/201271715505375798.html'\n",
      "3\n",
      "Indexing http://www.chinagrain.cn/mianpo/2016/8/29/20168291704174878.asp\n",
      "update urllist set posnegscore = 0.240973 where url = 'http://www.chinagrain.cn/mianpo/2016/8/29/20168291704174878.asp'\n",
      "4\n",
      "Indexing http://www.chinagrain.cn/douyou/2014/5/6/20145611312998244.shtml\n",
      "update urllist set posnegscore = 4.552232 where url = 'http://www.chinagrain.cn/douyou/2014/5/6/20145611312998244.shtml'\n",
      "5\n",
      "Indexing http://www.chinagrain.cn/doupo/2016/9/6/20169615204583451.asp\n",
      "update urllist set posnegscore = 5.816759 where url = 'http://www.chinagrain.cn/doupo/2016/9/6/20169615204583451.asp'\n",
      "6\n",
      "Indexing http://www.chinagrain.cn/biz/20164/201642815112829970.html\n",
      "update urllist set posnegscore = 0.427629 where url = 'http://www.chinagrain.cn/biz/20164/201642815112829970.html'\n",
      "7\n",
      "Indexing http://www.chinagrain.cn/yumi/2016/9/6/20169615334094661.asp\n",
      "update urllist set posnegscore = 1.626918 where url = 'http://www.chinagrain.cn/yumi/2016/9/6/20169615334094661.asp'\n",
      "8\n",
      "Indexing http://www.chinagrain.cn/xiaomai/2016/6/7/2016671017294535.shtml\n",
      "update urllist set posnegscore = 5.564426 where url = 'http://www.chinagrain.cn/xiaomai/2016/6/7/2016671017294535.shtml'\n",
      "9\n",
      "Indexing http://www.chinagrain.cn/about/tougao.html\n",
      "update urllist set posnegscore = 1.173734 where url = 'http://www.chinagrain.cn/about/tougao.html'\n",
      "10\n",
      "Indexing http://www.chinagrain.cn/douyou/2016/9/2/201692903625325.shtml\n",
      "update urllist set posnegscore = 0.245568 where url = 'http://www.chinagrain.cn/douyou/2016/9/2/201692903625325.shtml'\n",
      "11\n",
      "Indexing http://www.chinagrain.cn/doupo/2016/9/6/20169691488991.shtml\n",
      "update urllist set posnegscore = 0.728128 where url = 'http://www.chinagrain.cn/doupo/2016/9/6/20169691488991.shtml'\n",
      "12\n",
      "Indexing http://www.chinagrain.cn/huashengyou/2016/9/6/2016961212841211.shtml\n",
      "update urllist set posnegscore = 0.059042 where url = 'http://www.chinagrain.cn/huashengyou/2016/9/6/2016961212841211.shtml'\n",
      "13\n",
      "Indexing http://www.chinagrain.cn/about/law.html\n",
      "update urllist set posnegscore = -2.007065 where url = 'http://www.chinagrain.cn/about/law.html'\n",
      "14\n",
      "Indexing http://www.chinagrain.cn/biz/20146/20146189353990992.html\n",
      "update urllist set posnegscore = 3.842135 where url = 'http://www.chinagrain.cn/biz/20146/20146189353990992.html'\n",
      "15\n",
      "Indexing http://www.chinagrain.cn/zonglvyou/2014/9/2/2014921532735001.shtml\n",
      "update urllist set posnegscore = 2.558302 where url = 'http://www.chinagrain.cn/zonglvyou/2014/9/2/2014921532735001.shtml'\n",
      "16\n",
      "Indexing http://www.chinagrain.cn/mikangyou/2010/1/16/20101161642181546.html\n",
      "update urllist set posnegscore = 1.568771 where url = 'http://www.chinagrain.cn/mikangyou/2010/1/16/20101161642181546.html'\n",
      "17\n",
      "Indexing http://www.chinagrain.cn/dadou/2016/9/6/20169611114680427.shtml\n",
      "update urllist set posnegscore = -0.830738 where url = 'http://www.chinagrain.cn/dadou/2016/9/6/20169611114680427.shtml'\n",
      "18\n",
      "Indexing http://www.chinagrain.cn/u71560/2016/8/18/20168189594919671.shtml\n",
      "update urllist set posnegscore = 1.687834 where url = 'http://www.chinagrain.cn/u71560/2016/8/18/20168189594919671.shtml'\n",
      "19\n",
      "Indexing http://www.chinagrain.cn/daogu/2016/9/6/20169611271187640.asp\n",
      "update urllist set posnegscore = 2.648569 where url = 'http://www.chinagrain.cn/daogu/2016/9/6/20169611271187640.asp'\n",
      "20\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n"
     ]
    }
   ],
   "source": [
    "import searchengine\n",
    "crawler=searchengine.crawler('searchindex.db')\n",
    "crawler.createindextables()\n",
    "pages=['http://www.chinagrain.cn/']\n",
    "try:\n",
    "    crawler.crawl(pages,maxpages=20)\n",
    "except Exception,e:\n",
    "    print Exception,\":\",e\n",
    "finally:\n",
    "    crawler.calculatepagerank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-04\n",
      "templates\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<title>粮油市场挖掘</title>\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "\n",
      "<h1>This is homepage of Grain Analysis.</h1>\n",
      "<p>欢迎您访问粮油市场挖掘.</p>\n",
      "<ul>\n",
      "<p>利好消息:</p>\n",
      "<li>http://www.chinagrain.cn/zonglvyou/2016/9/7/20169710223224930.shtml 5.621836 pos</li>\n",
      "<li>http://www.chinagrain.cn/liangyou/2016/9/5/20169513582448889.shtml 5.421309 pos</li>\n",
      "<li>http://www.chinagrain.cn/xiaomai/2016/6/7/2016671017294535.shtml 4.815829 pos</li>\n",
      "<p>利空消息:</p>\n",
      "<li>http://www.chinagrain.cn/caiyou/2016/9/7/20169711153339235.shtml -0.534972 neg</li>\n",
      "\n",
      "<li>http://www.chinagrain.cn/ -0.251314 neg</li>\n",
      "\n",
      "<li>http://www.chinagrain.cn/biz/20164/201642815112829970.html 0.303898 neg</li>\n",
      "\n",
      "</ul>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "2016-09-0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1456a36d0d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetFrequentWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "import searchengine,web\n",
    "def fillFile(filepath):\n",
    "    f=open(filepath,'w')\n",
    "    e=searchengine.searcher('searchindex.db')\n",
    "    cursor= e.con.execute(\n",
    "            \" select * from urllist where posnegscore is not null order by posnegscore desc limit 3  \" )\n",
    "    for row in cursor:\n",
    "        f.write(row[0])\n",
    "        f.write(\"\\t\")\n",
    "        f.write(str(row[1]))\n",
    "        f.write(\"\\t\")\n",
    "        f.write(\"pos\")\n",
    "        f.write(\"\\n\")\n",
    "    cursor= e.con.execute(\n",
    "            \" select * from urllist where posnegscore is not null order by posnegscore asc limit 3  \" )\n",
    "    for row in cursor:\n",
    "        f.write(row[0])\n",
    "        f.write(\"\\t\")\n",
    "        f.write(str(row[1]))\n",
    "        f.write(\"\\t\")\n",
    "        f.write(\"neg\")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "def readFile(filepath):\n",
    "    fr=open(filepath,'r')\n",
    "    dataMat=[]\n",
    "    for line in fr.readlines():\n",
    "        curLine=line.strip().split('\\t')\n",
    "        lineArr=[]\n",
    "        lineArr.append(curLine[0])\n",
    "        lineArr.append(float(curLine[1]))\n",
    "        lineArr.append(curLine[2])\n",
    "        dataMat.append(lineArr)\n",
    "    poss=[x for x in dataMat if x[2]=='pos']\n",
    "    negs=[x for x in dataMat if x[2]=='neg']\n",
    "    return poss,negs\n",
    "        \n",
    "        \n",
    "import datetime, calendar,os\n",
    "lastSunday=datetime.date.today()\n",
    "oneday=datetime.timedelta(days=1)\n",
    "while lastSunday.weekday()!= calendar.SUNDAY:\n",
    "    lastSunday-=oneday\n",
    "print lastSunday\n",
    "filepath=\"data/\"+str(lastSunday)+\"pos.txt\";\n",
    "app_root = \"\"##########os.path.dirname(__file__)\n",
    "filepath=os.path.join(app_root, filepath)\n",
    "if not os.path.exists(filepath):\n",
    "    fillFile(filepath)\n",
    "poss,negs=readFile(filepath)\n",
    "templates_root = os.path.join(app_root, 'templates')\n",
    "print templates_root\n",
    "render = web.template.render(templates_root)\n",
    "print render.hello(poss,negs)\n",
    "\n",
    "#e.query(\"小麦\")\n",
    "import glob\n",
    "files=glob.glob('data/*.txt')\n",
    "filepath=files[0]\n",
    "print filepath[5:15]\n",
    "word_count= e.getFrequentWords()\n",
    "for row in word_count:\n",
    "    print row[0],',',row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "# Read the whole text.\n",
    " #此处原为处理英文文本，我们修改为传入中文数组\n",
    "#text = open(path.join(d, 'constitution.txt')).read()\n",
    "#frequencies = [(u'English',5),(u'小段同学',4),(u'曲小花',3),(u'中文分词',2),(u'样例',1)]\n",
    "import searchengine\n",
    "import matplotlib.pyplot as plt\n",
    "e=searchengine.searcher('searchindex.db')\n",
    "frequencies= e.getFrequentWords()\n",
    "# take relative word frequencies into account, lower max_font_size\n",
    "#wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate(text)\n",
    "wordcloud = WordCloud(font_path='/home/jamin/Documents/resource/msyh.ttf',background_color=\"white\",stopwords=STOPWORDS.add(u\"黄豆\"),max_font_size=40, relative_scaling=.25).fit_words(frequencies)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"data/date.jpg\")\n",
    "#plt.figure()\n",
    "#plt.imshow(wordcloud)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.734 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'bad'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import docclass\n",
    "c1=docclass.naivebayes(docclass.getwords)\n",
    "docclass.sampletrain(c1)\n",
    "c1.classify(u'疲软')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "长期来看或将抑制国内豆油的价格上涨\n",
      "目前国内豆油现货市场购销清淡\n",
      "增强了挺价信心\n",
      "近期收购需谨慎.\n",
      "市场沽空心理增强\n",
      "今日国内豆油现货价格预计以上涨为主\n",
      "利好信息:  [(0.23695425361155698, 'www.hello3.com'), (0.2812469131244193, 'www.hello4.com')]\n",
      "利空消息:  [(18.019158683881713, 'www.hello2.com'), (64.23676602193207, 'www.hello1.com')]\n"
     ]
    }
   ],
   "source": [
    "#already trained\n",
    "import docclass\n",
    "c1=docclass.naivebayes(docclass.getwords)\n",
    "docs=[]\n",
    "docs.append((u'长期来看或将抑制国内豆油的价格上涨','www.hello1.com'))\n",
    "docs.append((u'目前国内豆油现货市场购销清淡','www.hello4.com'))\n",
    "docs.append((u'增强了挺价信心','www.hello2.com'))\n",
    "docs.append((u'近期收购需谨慎.','www.hello5.com'))\n",
    "docs.append((u'市场沽空心理增强','www.hello3.com'))\n",
    "docs.append((u'今日国内豆油现货价格预计以上涨为主','www.hello0.com'))\n",
    "probs=[]\n",
    "for doc in docs:\n",
    "    print doc[0]\n",
    "    probs.append((c1.prob(doc[0],'good')/c1.prob(doc[0],'bad'),doc[1]))\n",
    "print u\"利好信息: \",sorted(probs)[0:2]\n",
    "print u\"利空消息: \",sorted(probs)[-3:-1]\n",
    "#print c1.prob(u'增强了挺价信心','bad')\n",
    "#print c1.prob(u'增强了挺价信心','good')\n",
    "#print c1.classify(u'增强了挺价信心')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello<div id=\"ArticleCnt\">\n",
      "<p style=\"TEXT-INDENT: 2em\"></p>\n",
      "<p style=\"text-indent:2em;\">\n",
      "<font color=\"#ff0000\">说明：您浏览的信息被限制浏览，浏览本信息可能需要您注册一个帐号才可以浏览,也可能是您的服务已到期或没有购买本类信息!入网热线:0451-88001128;88001138</font><br><br><b><font color=\"#ff0000\">信息说明：信息标题后带<img src=\"/img/2009/vip.gif\" style=\"width:10px;\">图标或VIP标志的均为VIP信息，需要本网会员才可浏览！</img></font></b><br><br>点此<a href=\"http://www.chinagrain.cn/member/register.html\" target=\"_blank\">注册用户账号&gt;&gt;&gt;</a><br>点此<a href=\"http://www.chinagrain.cn/about/service.html\" target=\"_blank\">查看服务介绍&gt;&gt;&gt;</a><br>点此<a href=\"http://www.chinagrain.cn/member/\" target=\"_blank\">登陆会员专区&gt;&gt;&gt;</a><br><br>\n",
      "<font color=\"#0000ff\">【信息内容摘要】</font><br>\r\n",
      "2016年9月6日山东潍坊DDGS价格行情（粮信网）\r\n",
      "\r\n",
      "</br></br></br></br></br></br></br></br></br></p>\n",
      "<p style=\"text-indent:2em;\">\n",
      "<style>\r\n",
      "#bdshare {width:564px;height:42px;}\r\n",
      "#bdshare img{border:0;padding-bottom:2px;}\r\n",
      "</style>\n",
      "<div class=\"bdsharebuttonbox\" id=\"bdshare\"><a class=\"bds_qzone\" data-cmd=\"qzone\" href=\"#\" title=\"分享到QQ空间\"></a><a class=\"bds_tsina\" data-cmd=\"tsina\" href=\"#\" title=\"分享到新浪微博\"></a><a class=\"bds_weixin\" data-cmd=\"weixin\" href=\"#\" title=\"分享到微信\"></a><a class=\"bds_sqq\" data-cmd=\"sqq\" href=\"#\" title=\"分享到QQ好友\"></a><a class=\"bds_baidu\" data-cmd=\"baidu\"></a>\n",
      "<a class=\"bds_renren\" data-cmd=\"renren\" href=\"#\" title=\"分享到人人\"></a>\n",
      "<a class=\"bds_tqq\" data-cmd=\"tqq\" href=\"#\" title=\"分享到腾讯微博\"></a>\n",
      "<a class=\"bds_tieba\" data-cmd=\"tieba\" href=\"#\" title=\"分享到百度贴吧\"></a>\n",
      "<a class=\"bds_copy\" data-cmd=\"copy\" href=\"#\" title=\"复制本文网址\"></a>\n",
      "<a class=\"bds_more\" data-cmd=\"more\" href=\"#\"></a><a class=\"bds_count\" data-cmd=\"count\"></a></div>\n",
      "<script>window._bd_share_config={\"common\":{\"bdSnsKey\":{},\"bdText\":\"\",\"bdMini\":\"2\",\"bdMiniList\":false,\"bdPic\":\"\",\"bdStyle\":\"0\",\"bdSize\":\"32\"},\"share\":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>\n",
      "</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import re\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from urlparse import urljoin\n",
    "c=urllib2.urlopen(\"http://www.chinagrain.cn/yumi/2016/9/6/20169615325093096.asp\")\n",
    "content=c.read()\n",
    "charset = chardet.detect(content[:400])['encoding']\n",
    "content = content.decode(charset, \"ignore\").encode('UTF-8')\n",
    "soup=BeautifulSoup(content, 'html.parser')\n",
    "text=\"hello\"\n",
    "for tag in soup.find_all('div', id=\"ArticleCnt\"):\n",
    "    text=\"\".join((text,str(tag)))\n",
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/home/jamin/anaconda2/bin/python python\n",
    "# -*-coding:utf-8 -*-\n",
    "import searchengine\n",
    "from os import path\n",
    "import searchengine\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import datetime, calendar,os\n",
    "\n",
    "def generateDB:\n",
    "    crawler=searchengine.crawler('searchindex.db')\n",
    "    crawler.createindextables()\n",
    "    pages=['http://www.chinagrain.cn/']\n",
    "    try:\n",
    "        crawler.crawl(pages,maxpages=100)\n",
    "    except Exception,e:\n",
    "        print Exception,\":\",e\n",
    "    finally:\n",
    "        crawler.calculatepagerank()\n",
    "def generatePosNegFile(filepath):\n",
    "    f=open(filepath,'w')\n",
    "    e=searchengine.searcher('searchindex.db')\n",
    "    cursor= e.con.execute(\n",
    "            \" select * from urllist where posnegscore is not null order by posnegscore desc limit 3  \" )\n",
    "    for row in cursor:\n",
    "        f.write(row[0])\n",
    "        f.write(\"\\t\")\n",
    "        f.write(str(row[1]))\n",
    "        f.write(\"\\t\")\n",
    "        f.write(\"pos\")\n",
    "        f.write(\"\\n\")\n",
    "    cursor= e.con.execute(\n",
    "            \" select * from urllist where posnegscore is not null order by posnegscore asc limit 3  \" )\n",
    "    for row in cursor:\n",
    "        f.write(row[0])\n",
    "        f.write(\"\\t\")\n",
    "        f.write(str(row[1]))\n",
    "        f.write(\"\\t\")\n",
    "        f.write(\"neg\")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "def generateFig(filePath):\n",
    "    e=searchengine.searcher('searchindex.db')\n",
    "    frequencies= e.getFrequentWords()\n",
    "    # take relative word frequencies into account, lower max_font_size\n",
    "    #wordcloud = WordCloud(max_font_size=40, relative_scaling=.5).generate(text)\n",
    "    wordcloud = WordCloud(font_path='/home/jamin/Documents/resource/msyh.ttf',background_color=\"white\",stopwords=STOPWORDS.add(u\"黄豆\"),max_font_size=40, relative_scaling=.25).fit_words(frequencies)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(filePath)\n",
    "if __name__=='__main__':\n",
    "    generateDB()\n",
    "    date=datetime.date.today()\n",
    "    filepath=\"data/\"+str(date)+\"pos_neg.txt\"\n",
    "    generatePosNegFile(filepath)\n",
    "    imgpath=\"data/\"+str(date)+\"word_cloud.jpg\"\n",
    "    generateFig(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/jamin/anaconda2/lib/python2.7/site-packages/wordcloud-1.2.1-py2.7-linux-i686.egg', '/home/jamin/anaconda2/lib/python2.7/site-packages/web.py-0.40.dev0-py2.7.egg', '/home/jamin/anaconda2/lib/python27.zip', '/home/jamin/anaconda2/lib/python2.7', '/home/jamin/anaconda2/lib/python2.7/plat-linux2', '/home/jamin/anaconda2/lib/python2.7/lib-tk', '/home/jamin/anaconda2/lib/python2.7/lib-old', '/home/jamin/anaconda2/lib/python2.7/lib-dynload', '/home/jamin/anaconda2/lib/python2.7/site-packages/Sphinx-1.3.5-py2.7.egg', '/home/jamin/anaconda2/lib/python2.7/site-packages/setuptools-20.3-py2.7.egg', '/home/jamin/anaconda2/lib/python2.7/site-packages', '/home/jamin/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/jamin/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# coding: UTF-8\n",
    "import os\n",
    " \n",
    "import sae\n",
    "import web\n",
    "import model\n",
    "import dataProc\n",
    "from weixinInterface import WeixinInterface\n",
    " \n",
    "urls = (\n",
    "'/', 'Hello',\n",
    "'/recommendPosNeg', 'recommendPosNeg',\n",
    "'/weixin','WeixinInterface',\n",
    "'/ck','feedback',\n",
    ")\n",
    " \n",
    "app_root = os.path.dirname(__file__)\n",
    "templates_root = os.path.join(app_root, 'templates')\n",
    "render = web.template.render(templates_root)\n",
    " \n",
    "class Hello:\n",
    "    def GET(self):\n",
    "    #print \"你好\"\n",
    "        return render.hello(\"你好\")\n",
    "    \n",
    "class recommendPosNeg:\n",
    "    def GET(self):\n",
    "    #print \"你好\"\n",
    "        poss,negs,generatedate=dataProc.readpos_neg()\n",
    "        return render.recommendPosNeg(poss,negs,generatedate)\n",
    "    \n",
    "class feedback:\n",
    "    def GET(self):\n",
    "        fkcon = model.get_fkcontent()\n",
    "        return render.checkfk(fkcon)\n",
    "    \n",
    "app = web.application(urls, globals()).wsgifunc()\n",
    "        \n",
    "application = sae.create_wsgi_app(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _*_ coding:utf-8 _*_\n",
    "import os,glob\n",
    "def readpos_neg():\n",
    "    files=glob.glob('data/*.txt')\n",
    "    filepath=files[0]\n",
    "    generatedate=filepath[5:15]\n",
    "    fr=open(filepath,'r')\n",
    "    date=\n",
    "    dataMat=[]\n",
    "    for line in fr.readlines():\n",
    "        curLine=line.strip().split('\\t')\n",
    "        lineArr=[]\n",
    "        lineArr.append(curLine[0])\n",
    "        lineArr.append(float(curLine[1]))\n",
    "        lineArr.append(curLine[2])\n",
    "        dataMat.append(lineArr)\n",
    "    poss=[x for x in dataMat if x[2]=='pos']\n",
    "    negs=[x for x in dataMat if x[2]=='neg']\n",
    "    return poss,negs,generatedate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
